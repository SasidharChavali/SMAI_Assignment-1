# Part - 1
## Given a dataset, a visualization on the data is performed and a distribution of each label in the dataset is plotted. 
## K-Nearest Neighbours Algorithm is implemented on the by taking the train dataset, and hyper parameter tuning is also performed.
## The Algorithm is then optimized by using the vectorization technique, which performs the distance computations using multi threading.

# Part - 2
## Given a dataset where each data point can have multiple labels. Firstly, all the distinct labels in the dataset are found and a distribution is plotted.
## With all the distinct labels obtained, a powerset is created and feature array is formed with the powerset. Then one-hot encoding is performed.
## With the obtained feature array, a decision tree classifier is built.
## Similarly, by creating a feature array with multilabels, another decision tree classifier is built. 
## Hyper parameter Tuning is performed for both cases, and the performance metrics are reported (f1-score, accuracy, precision, recall) 
